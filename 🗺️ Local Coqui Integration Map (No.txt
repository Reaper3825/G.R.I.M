ğŸ—ºï¸ Local Coqui Integration Map (No Server, No Cloud)
Stage 1 â€“ Environment Setup

Install Coqui TTS runtime:

pip install TTS


Verify it works offline:

tts --text "Hello Austin, GRIM is online." \
    --model_name tts_models/en/vctk/vits \
    --out_path test.wav


âœ… Confirms models can be pulled and used entirely local.

Stage 2 â€“ Persistent Bridge Process

Instead of calling Coqui fresh every time â†’ launch Python bridge once at GRIM startup.

Python bridge loads model into RAM and stays alive.

GRIM â†” Bridge communication via stdin/stdout JSON.

Reason: eliminates 3â€“5s reload penalty â†’ reduces latency to ~0.5â€“1s.

Stage 3 â€“ Python Bridge (tts_bridge.py)

Responsibilities:

Load Coqui TTS model once.

Listen for JSON commands from GRIM ({"text":"...", "speaker":"p225", "speed":1.0}).

Generate .wav file into a temp dir.

Return JSON with file path.

Can later be extended with emotion, language, etc.

Stage 4 â€“ GRIM Integration

In voice_speak.cpp:

Add initTTS() to spawn Python bridge (popen/_popen).

Add coquiSpeak() to:

Write JSON request â†’ stdin.

Read JSON response â† stdout.

Return path to .wav.

Pipe .wav into existing Voice::playAudio() (already SFML-based).

No duplication: GRIM doesnâ€™t care if itâ€™s Coqui, SAPI, or cloud â€” it just gets back a file to play.

Stage 5 â€“ Config Integration

Extend ai_config.json:

"voice": {
  "mode": "local",         // local = SAPI, coqui = new bridge
  "engine": "coqui",
  "speaker": "p225",
  "speed": 1.05,
  "rules": {
    "routine": "sapi",
    "banter": "coqui",
    "summary": "coqui"
  }
}


âœ… Lets you phase in Coqui gradually (e.g. only â€œbanterâ€ uses it at first).

Stage 6 â€“ Optimization (Optional)

GPU: Install PyTorch with CUDA â†’ inference ~3â€“6Ã— faster.

Model choice:

VITS (natural, heavier).

FastPitch (lighter, faster).

Quantization: Export to ONNX INT8 â†’ further ~30% speedup.

Streaming (future): Stream audio as it generates for zero-delay playback.

ğŸ”¹ Flow Once Integrated
GRIM command â†’ ResponseManager
   â†“
 decides category â†’ voice mode = coqui
   â†“
coquiSpeak() â†’ sends JSON to Python bridge
   â†“
Python bridge (warm model) â†’ generates temp .wav
   â†“
returns {"file":"grim_tts.wav"}
   â†“
Voice::playAudio("grim_tts.wav") via SFML
   â†“
Audio plays instantly


âš¡ End result: offline, human-like, <1s voice response, no servers, no cloud, no breakage of existing system.

Do you want me to sketch out the actual directory/boot changes (where tts_bridge.py lives, how GRIM spawns it, where temp WAVs get written), so youâ€™ve got a plug-and-play layout?

You said:
list the files that will need changes
ChatGPT said:

Alright â€” if weâ€™re doing local-only Coqui integration (Python bridge + GRIM piping into it), hereâ€™s the exact file impact inside your repo:

ğŸ“‚ Files That Will Need Changes
1. voice_speak.cpp

Add:

initTTS() â†’ spawns the Python bridge (tts_bridge.py) once at startup.

coquiSpeak(text) â†’ send JSON to Python, get .wav back.

Branch in Voice::speak() to call Coqui when "engine":"coqui".

Minor: still use existing Voice::playAudio() for playback.

2. voice_speak.hpp

Add declarations for initTTS() and coquiSpeak().

Possibly extend Voice::speak() signature if we pass params like speaker, speed.

3. ai_config.json (resources)

Extend voice config to support Coqui:

"voice": {
  "engine": "sapi",   // default
  "speaker": "p225",
  "speed": 1.0,
  "rules": {
    "routine": "sapi",
    "banter": "coqui",
    "summary": "coqui"
  }
}

4. response_manager.cpp

Already routes categories â†’ voice modes.

Needs to recognize "coqui" as a valid mode and forward to Voice::speak() with the right engine.

5. resources/

New file: tts_bridge.py

Lives in resources/python/ or similar.

Loads Coqui once, listens on stdin, returns JSON with file path.

6. (Optional) bootstrap_config.cpp

If you want defaults auto-merged, extend bootstrap logic to inject voice.engine = "sapi" if missing â†’ backwards compatible.

ğŸ”¹ Summary of Changed / New Files

âœ… Changed:

voice_speak.cpp

voice_speak.hpp

response_manager.cpp

ai_config.json

(optional) bootstrap_config.cpp

ğŸ†• New:

resources/python/tts_bridge.py